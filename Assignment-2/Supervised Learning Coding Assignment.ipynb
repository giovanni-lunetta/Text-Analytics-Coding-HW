{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4057c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5190453f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>teacher_utterance_number</th>\n",
       "      <th>text</th>\n",
       "      <th>gold_standard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10547</th>\n",
       "      <td>32</td>\n",
       "      <td>3929</td>\n",
       "      <td>48</td>\n",
       "      <td>All right. I want you to go to the next page. ...</td>\n",
       "      <td>math instruction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       transcript_id  utterance_id  teacher_utterance_number  \\\n",
       "10547             32          3929                        48   \n",
       "\n",
       "                                                    text     gold_standard  \n",
       "10547  All right. I want you to go to the next page. ...  math instruction  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"teacher_utterance_labels.xlsx\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc7315d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math_instruction\n",
       "1    8564\n",
       "0    2238\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"math_instruction\"] = np.where(df.gold_standard == \"math instruction\", 1, 0)\n",
    "df.math_instruction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afc8dad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>teacher_utterance_number</th>\n",
       "      <th>text</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>math_instruction</th>\n",
       "      <th>training_split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>We already know we have time we can say 10 and...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>26</td>\n",
       "      <td>197</td>\n",
       "      <td>was thata good time to find thed rods and use ...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>81</td>\n",
       "      <td>10</td>\n",
       "      <td>It's not the 14th That's the 17th Okay, who ca...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>Pencils behind you. Next to you, but not in yo...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>58</td>\n",
       "      <td>117</td>\n",
       "      <td>But that wouldn't be a good strategy to write ...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              transcript_id  teacher_utterance_number  \\\n",
       "utterance_id                                            \n",
       "4505                     37                        75   \n",
       "3252                     26                       197   \n",
       "9149                     81                        10   \n",
       "3089                     26                        32   \n",
       "6804                     58                       117   \n",
       "\n",
       "                                                           text  \\\n",
       "utterance_id                                                      \n",
       "4505          We already know we have time we can say 10 and...   \n",
       "3252          was thata good time to find thed rods and use ...   \n",
       "9149          It's not the 14th That's the 17th Okay, who ca...   \n",
       "3089          Pencils behind you. Next to you, but not in yo...   \n",
       "6804          But that wouldn't be a good strategy to write ...   \n",
       "\n",
       "                     gold_standard  math_instruction training_split  \n",
       "utterance_id                                                         \n",
       "4505              math instruction                 1           test  \n",
       "3252              math instruction                 1          train  \n",
       "9149              math instruction                 1            dev  \n",
       "3089          classroom management                 0          train  \n",
       "6804              math instruction                 1          train  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into training, dev, and testing at the transcript level\n",
    "\n",
    "TRAIN_RATIO = 0.6\n",
    "DEV_RATIO = 0.2\n",
    "TEST_RATIO = 0.2\n",
    "np.random.seed(5643)\n",
    "\n",
    "temp_df = df.copy()\n",
    "temp_df = temp_df[[\"transcript_id\", \"utterance_id\"]].groupby([\"transcript_id\"]).nunique()\n",
    "temp_df['random_number'] = np.random.randint(1, 10001, size=len(temp_df))\n",
    "temp_df = temp_df.sort_values(by = [\"random_number\"])\n",
    "\n",
    "\n",
    "size = len(temp_df)\n",
    "train_size = int(TRAIN_RATIO * size)\n",
    "dev_size = int(DEV_RATIO * size)\n",
    "test_size = size - train_size - dev_size\n",
    "\n",
    "temp_df[\"training_split\"] = [\"train\"]*train_size + [\"dev\"]*dev_size + [\"test\"]*test_size\n",
    "\n",
    "df = df.merge(temp_df[[\"training_split\"]], left_on = \"transcript_id\", right_index = True)\n",
    "df = df.set_index(\"utterance_id\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4517b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training_split\n",
       "train    6544\n",
       "dev      2273\n",
       "test     1985\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.training_split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f056d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(df[df.training_split == \"train\"].transcript_id.nunique())\n",
    "print(df[df.training_split == \"dev\"].transcript_id.nunique())\n",
    "print(df[df.training_split == \"test\"].transcript_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4737723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(df[df.training_split == \"train\"].index)\n",
    "dev_indices = list(df[df.training_split == \"dev\"].index)\n",
    "test_indices = list(df[df.training_split == \"test\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec1e7966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>teacher_utterance_number</th>\n",
       "      <th>text</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>math_instruction</th>\n",
       "      <th>training_split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>81</td>\n",
       "      <td>152</td>\n",
       "      <td>We're gonna put these aside. How many of you h...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>Let's count with him,Ready? So 1 2 3 4 5 6, oh...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>81</td>\n",
       "      <td>47</td>\n",
       "      <td>1 2 3 4 It does. And we knew that because they...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>81</td>\n",
       "      <td>185</td>\n",
       "      <td>and I took it apart. I did. I need you to plea...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>81</td>\n",
       "      <td>17</td>\n",
       "      <td>Do we say 63 day or what? 63rd day. remember w...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>Cross your arms again. Put your hands together...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>how me people check out a (inaudible) yeah go ...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>Alex could you help him  two keep that in mind...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>Hayden. We think it's minus three, three plus ...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>Do you think that this will happen every time ...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10802 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              transcript_id  teacher_utterance_number  \\\n",
       "utterance_id                                            \n",
       "9291                     81                       152   \n",
       "9168                     81                        29   \n",
       "9186                     81                        47   \n",
       "9324                     81                       185   \n",
       "9156                     81                        17   \n",
       "...                     ...                       ...   \n",
       "10906                   100                        25   \n",
       "10923                   100                        47   \n",
       "10888                   100                         3   \n",
       "10895                   100                        13   \n",
       "10902                   100                        20   \n",
       "\n",
       "                                                           text  \\\n",
       "utterance_id                                                      \n",
       "9291          We're gonna put these aside. How many of you h...   \n",
       "9168          Let's count with him,Ready? So 1 2 3 4 5 6, oh...   \n",
       "9186          1 2 3 4 It does. And we knew that because they...   \n",
       "9324          and I took it apart. I did. I need you to plea...   \n",
       "9156          Do we say 63 day or what? 63rd day. remember w...   \n",
       "...                                                         ...   \n",
       "10906         Cross your arms again. Put your hands together...   \n",
       "10923         how me people check out a (inaudible) yeah go ...   \n",
       "10888         Alex could you help him  two keep that in mind...   \n",
       "10895         Hayden. We think it's minus three, three plus ...   \n",
       "10902         Do you think that this will happen every time ...   \n",
       "\n",
       "                     gold_standard  math_instruction training_split  \n",
       "utterance_id                                                         \n",
       "9291              math instruction                 1            dev  \n",
       "9168              math instruction                 1            dev  \n",
       "9186          classroom management                 0            dev  \n",
       "9324          classroom management                 0            dev  \n",
       "9156              math instruction                 1            dev  \n",
       "...                            ...               ...            ...  \n",
       "10906         classroom management                 0            dev  \n",
       "10923         classroom management                 0            dev  \n",
       "10888             math instruction                 1            dev  \n",
       "10895             math instruction                 1            dev  \n",
       "10902             math instruction                 1            dev  \n",
       "\n",
       "[10802 rows x 6 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7836adf",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d0f56",
   "metadata": {},
   "source": [
    "#### Lematization and Removal of Domain Specific Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "be8385be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data (if not already downloaded)\n",
    "nltk.download('punkt') # For word_tokenize\n",
    "nltk.download('wordnet') # For WordNetLemmatizer\n",
    "\n",
    "# Custom stop words list\n",
    "stop_words_classroom = [\n",
    "    \"a\", \"an\", \"the\", # Articles\n",
    "    \"he\", \"she\", \"it\", \"they\", # Pronouns\n",
    "    \"in\", \"on\", \"at\", \"from\", # Prepositions\n",
    "    \"and\", \"but\", \"or\", # Conjunctions\n",
    "    \"be\", \"have\", \"do\", \"is\", \"am\", \"are\", \"was\", \"were\", # Auxiliary Verbs\n",
    "    \"say\", \"go\", \"get\", \"see\", \"know\", \"think\", # Other Common Verbs\n",
    "    \"some\", \"any\", \"much\", \"many\", # Quantifiers\n",
    "    \"always\", \"often\", \"sometimes\", \"never\", # Adverbs of Frequency\n",
    "    \"can\", \"could\", \"may\", \"might\", \"will\", \"would\", \"should\", # Modal Verbs\n",
    "    \"well\", \"so\", \"um\", \"uh\", \"like\" # Filler Words\n",
    "]\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization and lemmatization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
    "    \n",
    "    # Stop words removal\n",
    "    filtered_tokens = [token for token in lemmatized_tokens if token not in stop_words_classroom]\n",
    "    \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "df['lematized_no_stop_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "657043e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>teacher_utterance_number</th>\n",
       "      <th>text</th>\n",
       "      <th>gold_standard</th>\n",
       "      <th>math_instruction</th>\n",
       "      <th>training_split</th>\n",
       "      <th>lematized_no_stop_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>81</td>\n",
       "      <td>152</td>\n",
       "      <td>We're gonna put these aside. How many of you h...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "      <td>we 're gon na put these aside . how of you all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>81</td>\n",
       "      <td>29</td>\n",
       "      <td>Let's count with him,Ready? So 1 2 3 4 5 6, oh...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "      <td>let 's count with him , ready ? 1 2 3 4 5 6 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>81</td>\n",
       "      <td>47</td>\n",
       "      <td>1 2 3 4 It does. And we knew that because they...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "      <td>1 2 3 4 doe . we knew that because 're related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>81</td>\n",
       "      <td>185</td>\n",
       "      <td>and I took it apart. I did. I need you to plea...</td>\n",
       "      <td>classroom management</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "      <td>i took apart . i did . i need you to please to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>81</td>\n",
       "      <td>17</td>\n",
       "      <td>Do we say 63 day or what? 63rd day. remember w...</td>\n",
       "      <td>math instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "      <td>we 63 day what ? 63rd day . remember we 're ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              transcript_id  teacher_utterance_number  \\\n",
       "utterance_id                                            \n",
       "9291                     81                       152   \n",
       "9168                     81                        29   \n",
       "9186                     81                        47   \n",
       "9324                     81                       185   \n",
       "9156                     81                        17   \n",
       "\n",
       "                                                           text  \\\n",
       "utterance_id                                                      \n",
       "9291          We're gonna put these aside. How many of you h...   \n",
       "9168          Let's count with him,Ready? So 1 2 3 4 5 6, oh...   \n",
       "9186          1 2 3 4 It does. And we knew that because they...   \n",
       "9324          and I took it apart. I did. I need you to plea...   \n",
       "9156          Do we say 63 day or what? 63rd day. remember w...   \n",
       "\n",
       "                     gold_standard  math_instruction training_split  \\\n",
       "utterance_id                                                          \n",
       "9291              math instruction                 1            dev   \n",
       "9168              math instruction                 1            dev   \n",
       "9186          classroom management                 0            dev   \n",
       "9324          classroom management                 0            dev   \n",
       "9156              math instruction                 1            dev   \n",
       "\n",
       "                                         lematized_no_stop_text  \n",
       "utterance_id                                                     \n",
       "9291          we 're gon na put these aside . how of you all...  \n",
       "9168          let 's count with him , ready ? 1 2 3 4 5 6 , ...  \n",
       "9186          1 2 3 4 doe . we knew that because 're related...  \n",
       "9324          i took apart . i did . i need you to please to...  \n",
       "9156          we 63 day what ? 63rd day . remember we 're ta...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d59ee3",
   "metadata": {},
   "source": [
    "### TF-IDF after Lemmatization & Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb03b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 0.01)\n",
    "\n",
    "# Fit and transform the processed text\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['lematized_no_stop_text'])\n",
    "tfidf_matrix = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8843550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10s</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>0.121956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228257</td>\n",
       "      <td>0.211335</td>\n",
       "      <td>0.241161</td>\n",
       "      <td>0.230335</td>\n",
       "      <td>0.235945</td>\n",
       "      <td>0.256515</td>\n",
       "      <td>0.267562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>0.141072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101656</td>\n",
       "      <td>0.173579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047629</td>\n",
       "      <td>0.406637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129759</td>\n",
       "      <td>0.332347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057663</td>\n",
       "      <td>0.098461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10802 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    10  100  10s        11        12        13        14  \\\n",
       "utterance_id                                                               \n",
       "9291          0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "9168          0.121956  0.0  0.0  0.228257  0.211335  0.241161  0.230335   \n",
       "9186          0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "9324          0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "9156          0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "...                ...  ...  ...       ...       ...       ...       ...   \n",
       "10906         0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "10923         0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "10888         0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "10895         0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "10902         0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                    15        16        17  ...  wrote      yeah  yep  yes  \\\n",
       "utterance_id                                ...                              \n",
       "9291          0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "9168          0.235945  0.256515  0.267562  ...    0.0  0.000000  0.0  0.0   \n",
       "9186          0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "9324          0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "9156          0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "...                ...       ...       ...  ...    ...       ...  ...  ...   \n",
       "10906         0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "10923         0.000000  0.000000  0.000000  ...    0.0  0.106725  0.0  0.0   \n",
       "10888         0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "10895         0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "10902         0.000000  0.000000  0.000000  ...    0.0  0.000000  0.0  0.0   \n",
       "\n",
       "              yesterday  yet       you      your  yours  zero  \n",
       "utterance_id                                                   \n",
       "9291                0.0  0.0  0.351078  0.000000    0.0   0.0  \n",
       "9168                0.0  0.0  0.000000  0.000000    0.0   0.0  \n",
       "9186                0.0  0.0  0.165237  0.141072    0.0   0.0  \n",
       "9324                0.0  0.0  0.101656  0.173579    0.0   0.0  \n",
       "9156                0.0  0.0  0.000000  0.000000    0.0   0.0  \n",
       "...                 ...  ...       ...       ...    ...   ...  \n",
       "10906               0.0  0.0  0.047629  0.406637    0.0   0.0  \n",
       "10923               0.0  0.0  0.129759  0.332347    0.0   0.0  \n",
       "10888               0.0  0.0  0.191142  0.000000    0.0   0.0  \n",
       "10895               0.0  0.0  0.000000  0.000000    0.0   0.0  \n",
       "10902               0.0  0.0  0.057663  0.098461    0.0   0.0  \n",
       "\n",
       "[10802 rows x 343 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e60773",
   "metadata": {},
   "source": [
    "### Count Vectorizer after Lemmatization & Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4ed980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(min_df = 0.01)\n",
    "X = vec.fit_transform(df['lematized_no_stop_text'])\n",
    "cv_matrix = pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b35fe99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10s</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utterance_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9186</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10902</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10802 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              10  100  10s  11  12  13  14  15  16  17  ...  wrote  yeah  yep  \\\n",
       "utterance_id                                            ...                     \n",
       "9291           0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "9168           1    0    0   1   1   1   1   1   1   1  ...      0     0    0   \n",
       "9186           0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "9324           0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "9156           0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "...           ..  ...  ...  ..  ..  ..  ..  ..  ..  ..  ...    ...   ...  ...   \n",
       "10906          0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "10923          0    0    0   0   0   0   0   0   0   0  ...      0     1    0   \n",
       "10888          0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "10895          0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "10902          0    0    0   0   0   0   0   0   0   0  ...      0     0    0   \n",
       "\n",
       "              yes  yesterday  yet  you  your  yours  zero  \n",
       "utterance_id                                               \n",
       "9291            0          0    0    5     0      0     0  \n",
       "9168            0          0    0    0     0      0     0  \n",
       "9186            0          0    0    4     2      0     0  \n",
       "9324            0          0    0    1     1      0     0  \n",
       "9156            0          0    0    0     0      0     0  \n",
       "...           ...        ...  ...  ...   ...    ...   ...  \n",
       "10906           0          0    0    1     5      0     0  \n",
       "10923           0          0    0    4     6      0     0  \n",
       "10888           0          0    0    7     0      0     0  \n",
       "10895           0          0    0    0     0      0     0  \n",
       "10902           0          0    0    1     1      0     0  \n",
       "\n",
       "[10802 rows x 343 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fab942",
   "metadata": {},
   "source": [
    "## **Because we are going to perform 5-Fold Cross Validation, we do not need a seperate holdout dev set. This dev set will be created from the train set during the cross validation process. Therefore, we will merge the train_idicies and dev_indices into a single set of indices for the cross validation process instead of just throwing it away.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c42ecd",
   "metadata": {},
   "source": [
    "### X & y Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b9f0705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_X = tfidf_matrix[tfidf_matrix.index.isin(train_indices)]\n",
    "tf_train_y = df[df.index.isin(train_indices)].math_instruction\n",
    "\n",
    "cv_train_X = cv_matrix[cv_matrix.index.isin(train_indices)]\n",
    "cv_train_y = df[df.index.isin(train_indices)].math_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3eaf63",
   "metadata": {},
   "source": [
    "### X & y Dev Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "581542e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dev_X = tfidf_matrix[tfidf_matrix.index.isin(dev_indices)]\n",
    "tf_dev_y = df[df.index.isin(dev_indices)].math_instruction\n",
    "\n",
    "cv_dev_X = cv_matrix[cv_matrix.index.isin(dev_indices)]\n",
    "cv_dev_y = df[df.index.isin(dev_indices)].math_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84d6040",
   "metadata": {},
   "source": [
    "### Combining Train & Dev Indices for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "111224d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dev_X = tfidf_matrix[tfidf_matrix.index.isin(train_indices + dev_indices)]\n",
    "tf_train_dev_y = df[df.index.isin(train_indices + dev_indices)].math_instruction\n",
    "\n",
    "cv_train_dev_X = cv_matrix[cv_matrix.index.isin(train_indices + dev_indices)]\n",
    "cv_train_dev_y = df[df.index.isin(train_indices + dev_indices)].math_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c7350",
   "metadata": {},
   "source": [
    "### X & y Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d3ec616",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_X = tfidf_matrix[tfidf_matrix.index.isin(test_indices)]\n",
    "tf_test_y = df[df.index.isin(test_indices)].math_instruction\n",
    "\n",
    "cv_test_X = cv_matrix[cv_matrix.index.isin(test_indices)]\n",
    "cv_test_y = df[df.index.isin(test_indices)].math_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e41f33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_token_tf_train_dev = df.merge(tf_train_dev_X, left_index = True, right_index=True)\n",
    "\n",
    "df_token_cv_train_dev = df.merge(cv_train_dev_X, left_index = True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a451d7",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for TF-IDF Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "40f4e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bb0a25d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 400}\n",
      "Accuracy: 0.8583369995600528\n",
      "Precision: 0.8569284642321161\n",
      "Recall: 0.9794168096054888\n",
      "F1: 0.9140875133404482\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "tf_random_forest_model_1 = RandomForestClassifier(random_state=5643)\n",
    "\n",
    "# Define the grid of parameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search_cv = GridSearchCV(estimator=tf_random_forest_model_1, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search_cv.fit(tf_train_X, tf_train_y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_cv.best_params_)\n",
    "\n",
    "# Access the best model\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Use the best model for predictions\n",
    "predictions = best_model.predict(tf_dev_X)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_true = tf_dev_y, y_pred = predictions, )\n",
    "precision = precision_score(y_true = tf_dev_y, y_pred = predictions)\n",
    "recall = recall_score(y_true = tf_dev_y, y_pred = predictions)\n",
    "f1 = f1_score(y_true = tf_dev_y, y_pred = predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabefb4",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for CV Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78aedbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 100}\n",
      "Accuracy: 0.8644962604487462\n",
      "Precision: 0.861878453038674\n",
      "Recall: 0.9811320754716981\n",
      "F1: 0.9176470588235295\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "cv_random_forest_model_1 = RandomForestClassifier(random_state=5643)\n",
    "\n",
    "# Define the grid of parameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search_cv = GridSearchCV(estimator=cv_random_forest_model_1, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search_cv.fit(cv_train_X, cv_train_y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_cv.best_params_)\n",
    "\n",
    "# Access the best model\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Use the best model for predictions\n",
    "predictions = best_model.predict(cv_dev_X)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_true = cv_dev_y, y_pred = predictions, )\n",
    "precision = precision_score(y_true = cv_dev_y, y_pred = predictions)\n",
    "recall = recall_score(y_true = cv_dev_y, y_pred = predictions)\n",
    "f1 = f1_score(y_true = cv_dev_y, y_pred = predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90697a6f",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for TF-IDF Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a8cc0d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False}\n",
      "Accuracy: 0.8675758908930928\n",
      "Precision: 0.8667679837892603\n",
      "Recall: 0.978273299028016\n",
      "F1: 0.9191512221326886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "\n",
    "# Define the Random Forest model\n",
    "tf_random_forest_model_2 = RandomForestClassifier(random_state=5643)\n",
    "\n",
    "# Define the grid of parameters to search over\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False] \n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search_cv = GridSearchCV(estimator=tf_random_forest_model_2, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search_cv.fit(tf_train_X, tf_train_y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_cv.best_params_)\n",
    "\n",
    "# Access the best model\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Use the best model for predictions\n",
    "predictions = best_model.predict(tf_dev_X)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_true = tf_dev_y, y_pred = predictions, )\n",
    "precision = precision_score(y_true = tf_dev_y, y_pred = predictions)\n",
    "recall = recall_score(y_true = tf_dev_y, y_pred = predictions)\n",
    "f1 = f1_score(y_true = tf_dev_y, y_pred = predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b1382",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for TF-IDF Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "715adde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False}\n",
      "Accuracy: 0.8702155741311043\n",
      "Precision: 0.8709183673469387\n",
      "Recall: 0.9759862778730704\n",
      "F1: 0.9204637368562955\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "cv_random_forest_model_2 = RandomForestClassifier(random_state=5643)\n",
    "\n",
    "# Define the grid of parameters to search over\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
    "}\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search_cv = GridSearchCV(estimator=cv_random_forest_model_2, param_grid=param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search_cv.fit(cv_train_X, cv_train_y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_cv.best_params_)\n",
    "\n",
    "# Access the best model\n",
    "best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "# Use the best model for predictions\n",
    "predictions = best_model.predict(cv_dev_X)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_true = cv_dev_y, y_pred = predictions, )\n",
    "precision = precision_score(y_true = cv_dev_y, y_pred = predictions)\n",
    "recall = recall_score(y_true = cv_dev_y, y_pred = predictions)\n",
    "f1 = f1_score(y_true = cv_dev_y, y_pred = predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389af68",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d74f48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b144fe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3,4,5]  # Maximum depth of the individual trees\n",
    "}\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "boosted_forest = GradientBoostingClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(boosted_forest, param_grid, cv=StratifiedKFold(n_splits=5), scoring = f1_scorer)\n",
    "grid_search.fit(tf_train_X, tf_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cf6a0856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_gb_depth_model = GradientBoostingClassifier(max_depth = best_params[\"max_depth\"])\n",
    "tf_gb_depth_model.fit(tf_train_X, tf_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d4434d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3,4,5]  # Maximum depth of the individual trees\n",
    "}\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "boosted_forest = GradientBoostingClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(boosted_forest, param_grid, cv=StratifiedKFold(n_splits=5), scoring = f1_scorer)\n",
    "grid_search.fit(cv_train_X, cv_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "37f806a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gb_depth_model = GradientBoostingClassifier(max_depth = best_params[\"max_depth\"])\n",
    "cv_gb_depth_model.fit(cv_train_X, cv_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37b55b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 150],  # Number of boosting stages\n",
    "}\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "boosted_forest = GradientBoostingClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(boosted_forest, param_grid, cv=StratifiedKFold(n_splits=5), scoring = f1_scorer)\n",
    "grid_search.fit(tf_train_X, tf_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac0974bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=150)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_gb_estimators_model = GradientBoostingClassifier(n_estimators = best_params[\"n_estimators\"])\n",
    "tf_gb_estimators_model.fit(tf_train_X, tf_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d9682fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 150],  # Number of boosting stages\n",
    "}\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "boosted_forest = GradientBoostingClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(boosted_forest, param_grid, cv=StratifiedKFold(n_splits=5), scoring = f1_scorer)\n",
    "grid_search.fit(cv_train_X, cv_train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "db8b9ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=150)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_gb_estimators_model = GradientBoostingClassifier(n_estimators = best_params[\"n_estimators\"])\n",
    "cv_gb_estimators_model.fit(cv_train_X, cv_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0dfac2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8609766827980643\n",
      "Precision: 0.8687596500257334\n",
      "Recall: 0.9651229273870783\n",
      "F1: 0.9144095341278439\n"
     ]
    }
   ],
   "source": [
    "test_predictions = tf_gb_depth_model.predict(tf_dev_X)\n",
    "\n",
    "accuracy = accuracy_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "precision = precision_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "recall = recall_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "f1 = f1_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "90c8626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8622965244170699\n",
      "Precision: 0.8751306165099269\n",
      "Recall: 0.9576901086335049\n",
      "F1: 0.9145509145509144\n"
     ]
    }
   ],
   "source": [
    "test_predictions = cv_gb_depth_model.predict(cv_dev_X)\n",
    "\n",
    "accuracy = accuracy_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "precision = precision_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "recall = recall_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "f1 = f1_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f54effcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.857017157941047\n",
      "Precision: 0.8643807574206755\n",
      "Recall: 0.9656946826758147\n",
      "F1: 0.912233324331623\n"
     ]
    }
   ],
   "source": [
    "test_predictions = tf_gb_estimators_model.predict(tf_dev_X)\n",
    "\n",
    "accuracy = accuracy_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "precision = precision_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "recall = recall_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "f1 = f1_score(y_true = tf_dev_y, y_pred = test_predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a59d2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8561372635283766\n",
      "Precision: 0.8646153846153846\n",
      "Recall: 0.9639794168096055\n",
      "F1: 0.9115977291159773\n"
     ]
    }
   ],
   "source": [
    "test_predictions = cv_gb_estimators_model.predict(cv_dev_X)\n",
    "\n",
    "accuracy = accuracy_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "precision = precision_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "recall = recall_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "f1 = f1_score(y_true = cv_dev_y, y_pred = test_predictions)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529628f",
   "metadata": {},
   "source": [
    "### Logistic Regression with LASSO penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6e736",
   "metadata": {},
   "source": [
    "First we will run a logistic regression with a penalty on the L1 norm on the size of $\\beta$. We implement 5-fold cross validation to pick the optimal $\\lambda$ value. We do this for both the tfidf and the count vectorizer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5df84e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lasso_model = LogisticRegression(penalty='l1', random_state = 5643, solver = 'saga')\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "tf_grid_search_lasso = GridSearchCV(lasso_model, param_grid, cv=StratifiedKFold(n_splits=5), scoring = \"accuracy\")\n",
    "tf_grid_search_lasso.fit(tf_train_X, tf_train_y)\n",
    "\n",
    "tf_best_params_lasso = tf_grid_search_lasso.best_params_\n",
    "tf_best_score_lasso = tf_grid_search_lasso.best_score_\n",
    "#print(tf_best_params_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d1a9f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "79b10543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8891333040035195\n",
      "Precision:  0.9043760129659644\n",
      "Recall:  0.9571183533447685\n",
      "F1 Score:  0.93\n"
     ]
    }
   ],
   "source": [
    "tf_dev_preds_lasso = tf_grid_search_lasso.predict(tf_dev_X)\n",
    "tf_lasso_acc = accuracy_score(y_true = tf_dev_y, y_pred = tf_dev_preds_lasso)\n",
    "tf_lasso_pre = precision_score(y_true = tf_dev_y, y_pred = tf_dev_preds_lasso)\n",
    "tf_lasso_rec = recall_score(y_true = tf_dev_y, y_pred = tf_dev_preds_lasso)\n",
    "tf_lasso_f1 = f1_score(y_true = tf_dev_y, y_pred = tf_dev_preds_lasso)\n",
    "print(\"Accuracy: \", tf_lasso_acc)\n",
    "print(\"Precision: \", tf_lasso_pre)\n",
    "print(\"Recall: \", tf_lasso_rec)\n",
    "print(\"F1 Score: \", tf_lasso_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769b3ee",
   "metadata": {},
   "source": [
    "We repeat the methods above but with the Count Vectorizer method instead of tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e34344c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(penalty='l1', random_state = 5643, solver = 'saga')\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "cv_grid_search_lasso = GridSearchCV(logistic_model, param_grid, cv=StratifiedKFold(n_splits=5), scoring = \"accuracy\")\n",
    "cv_grid_search_lasso.fit(cv_train_X, cv_train_y)\n",
    "\n",
    "cv_best_params_lasso = cv_grid_search_lasso.best_params_\n",
    "cv_best_score_lasso = cv_grid_search_lasso.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a56b5158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8891333040035195\n",
      "Precision:  0.9128516271373415\n",
      "Recall:  0.9462550028587764\n",
      "F1 Score:  0.9292532285233015\n"
     ]
    }
   ],
   "source": [
    "cv_dev_preds_lasso = cv_grid_search_lasso.predict(cv_dev_X)\n",
    "cv_lasso_acc = accuracy_score(y_true = cv_dev_y, y_pred = cv_dev_preds_lasso)\n",
    "cv_lasso_pre = precision_score(y_true = cv_dev_y, y_pred = cv_dev_preds_lasso)\n",
    "cv_lasso_rec = recall_score(y_true = cv_dev_y, y_pred = cv_dev_preds_lasso)\n",
    "cv_lasso_f1 = f1_score(y_true = cv_dev_y, y_pred = cv_dev_preds_lasso)\n",
    "print(\"Accuracy: \", cv_lasso_acc)\n",
    "print(\"Precision: \", cv_lasso_pre)\n",
    "print(\"Recall: \", cv_lasso_rec)\n",
    "print(\"F1 Score: \", cv_lasso_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fb1b3",
   "metadata": {},
   "source": [
    "Next we will run a logistic regression with a penalty on the L2 norm on the size of $\\beta$. We implement 5-fold cross validation to pick the optimal $\\lambda$ value. We do this for both the tfidf and the count vectorizer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ea7803d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ridge_model = LogisticRegression(penalty='l2', random_state = 5643, solver = 'saga')\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "tf_grid_search_ridge = GridSearchCV(ridge_model, param_grid, cv=StratifiedKFold(n_splits=5), scoring = \"accuracy\")\n",
    "tf_grid_search_ridge.fit(tf_train_X, tf_train_y)\n",
    "\n",
    "tf_best_params_ridge = tf_grid_search_ridge.best_params_\n",
    "tf_best_score_ridge = tf_grid_search_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "17f78c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8926528816542015\n",
      "Precision:  0.9155162893429045\n",
      "Recall:  0.9479702687249857\n",
      "F1 Score:  0.9314606741573035\n"
     ]
    }
   ],
   "source": [
    "tf_dev_preds_ridge = tf_grid_search_ridge.predict(tf_dev_X)\n",
    "tf_ridge_acc = accuracy_score(y_true = tf_dev_y, y_pred = tf_dev_preds_ridge)\n",
    "tf_ridge_pre = precision_score(y_true = tf_dev_y, y_pred = tf_dev_preds_ridge)\n",
    "tf_ridge_rec = recall_score(y_true = tf_dev_y, y_pred = tf_dev_preds_ridge)\n",
    "tf_ridge_f1 = f1_score(y_true = tf_dev_y, y_pred = tf_dev_preds_ridge)\n",
    "print(\"Accuracy: \", tf_ridge_acc)\n",
    "print(\"Precision: \", tf_ridge_pre)\n",
    "print(\"Recall: \", tf_ridge_rec)\n",
    "print(\"F1 Score: \", tf_ridge_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d647611",
   "metadata": {},
   "source": [
    "We repeat the methods above but with the Count Vectorizer method instead of tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2792fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/giovanni-lunetta/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ridge_model = LogisticRegression(penalty='l2', random_state = 5643, solver = 'saga')\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "cv_grid_search_ridge = GridSearchCV(ridge_model, param_grid, cv=StratifiedKFold(n_splits=5), scoring = \"accuracy\")\n",
    "cv_grid_search_ridge.fit(cv_train_X, cv_train_y)\n",
    "\n",
    "cv_best_params_ridge = cv_grid_search_ridge.best_params_\n",
    "cv_best_score_ridge = cv_grid_search_ridge.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71e8aaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8860536735591729\n",
      "Precision:  0.9053318824809575\n",
      "Recall:  0.9514008004574043\n",
      "F1 Score:  0.9277948146083077\n"
     ]
    }
   ],
   "source": [
    "cv_dev_preds_ridge = cv_grid_search_ridge.predict(cv_dev_X)\n",
    "cv_ridge_acc = accuracy_score(y_true = cv_dev_y, y_pred = cv_dev_preds_ridge)\n",
    "cv_ridge_pre = precision_score(y_true = cv_dev_y, y_pred = cv_dev_preds_ridge)\n",
    "cv_ridge_rec = recall_score(y_true = cv_dev_y, y_pred = cv_dev_preds_ridge)\n",
    "cv_ridge_f1 = f1_score(y_true = cv_dev_y, y_pred = cv_dev_preds_ridge)\n",
    "print(\"Accuracy: \", cv_ridge_acc)\n",
    "print(\"Precision: \", cv_ridge_pre)\n",
    "print(\"Recall: \", cv_ridge_rec)\n",
    "print(\"F1 Score: \", cv_ridge_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c30625",
   "metadata": {},
   "source": [
    "# Evaluate best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c16a881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9037783375314862\n",
      "Precision:  0.9214285714285714\n",
      "Recall:  0.9632856253889235\n",
      "F1 Score:  0.9418923030118649\n"
     ]
    }
   ],
   "source": [
    "tf_test_preds_ridge = tf_grid_search_ridge.predict(tf_test_X)\n",
    "tf_ridge_acc = accuracy_score(y_true = tf_test_y, y_pred = tf_test_preds_ridge)\n",
    "tf_ridge_pre = precision_score(y_true = tf_test_y, y_pred = tf_test_preds_ridge)\n",
    "tf_ridge_rec = recall_score(y_true = tf_test_y, y_pred = tf_test_preds_ridge)\n",
    "tf_ridge_f1 = f1_score(y_true = tf_test_y, y_pred = tf_test_preds_ridge)\n",
    "print(\"Accuracy: \", tf_ridge_acc)\n",
    "print(\"Precision: \", tf_ridge_pre)\n",
    "print(\"Recall: \", tf_ridge_rec)\n",
    "print(\"F1 Score: \", tf_ridge_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
